import os
import cv2
import easyocr
from google.cloud import vision
from csv import Dialect
from cv2 import threshold
from matplotlib.pyplot import contour, gray
import pytesseract
import cv2
import numpy as np

os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "dsa3101-2210-12-math-0c5fbe8196aa.json"

def CloudVisionTextExtractor(handwritings):
    # convert image from numpy to bytes for submittion to Google Cloud Vision
    _, encoded_image = cv2.imencode('.png', handwritings)
    content = encoded_image.tobytes()
    image = vision.Image(content=content)
    
    # feed handwriting image segment to the Google Cloud Vision API
    client = vision.ImageAnnotatorClient()
    response = client.document_text_detection(image=image)
    
    return response

def getTextFromVisionResponse(response):
    texts = []
    for page in response.full_text_annotation.pages:
        for i, block in enumerate(page.blocks):  
            for paragraph in block.paragraphs:       
                for word in paragraph.words:
                    word_text = ''.join([symbol.text for symbol in word.symbols])
                    texts.append(word_text)

    return ' '.join(texts)


#handwritings = segments[2]

#Need to install tesseract-ocr and see the location of the .exe file
#pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe'

def noise_removal(img):
    kernel = np.ones((1,1), np.uint8)
    img = cv2.dilate(img, kernel, iterations=1)
    img = cv2.erode(img, kernel, iterations=1)
    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)
    img = cv2.medianBlur(img, 3)
    return img

def thin_font(img):
    img = cv2.bitwise_not(img)
    kernel = np.ones((2, 2), np.uint8)
    img = cv2.erode(img, kernel, iterations=1)
    img = cv2.bitwise_not(img)
    return img

def thick_font(img):
    img = cv2.bitwise_not(img)
    kernel = np.ones((2, 2), np.uint8)
    img = cv2.dilate(img, kernel, iterations=1)
    img = cv2.bitwise_not(img)
    return img

#Simple slicing box
for count in range(1):
    img = cv2.imread(f"modified-data/page{count}.jpg")
    hImg, wImg, _ =  img.shape
    i = 0
    stepH = (int)(hImg / 5)
    stepW = (int)(wImg / 5)
    while i <= hImg:
        j = 0
        while j <= wImg:
            tem_img = img[i:i+stepH, j : j + stepW]
            cv2.imwrite(f"kernel_data/detected{i + j}.png", tem_img)
            gray_image = cv2.cvtColor(tem_img, cv2.COLOR_BGR2GRAY)
            thresh, im_bw = cv2.threshold(gray_image, 210, 220, cv2.THRESH_BINARY)
            no_noise = thin_font(im_bw)

            boxes = pytesseract.image_to_boxes(no_noise)
            for b in boxes.splitlines():
                b = b.split(' ')
                x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])
                cv2.rectangle(img, (x + j, stepH - y + i), (w + j, stepH - h + i), (50, 50, 255), 1)
                cv2.putText(img, b[0], (x + j, stepH - y + i + 13), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 205, 50), 1)
            j += stepW
        i += stepH

    cv2.imwrite(f"temp/detected{count}.png", img)
    print(count)

#reader = easyocr.Reader(['en'], gpu=True)
handwritings = cv2.imread("modified-data/page2.jpg")
responses = CloudVisionTextExtractor(handwritings)
handwrittenText = getTextFromVisionResponse(responses)
print(handwrittenText)

