{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PDF to Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Anaconda like me:\n",
    "[CONDA CHEAT SHEET](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiL1umVjMT6AhWHELcAHR9YC7sQFnoECBAQAQ&url=https%3A%2F%2Fdocs.conda.io%2Fprojects%2Fconda%2Fen%2F4.6.0%2F_downloads%2F52a95608c49671267e40c689e0bc00ca%2Fconda-cheatsheet.pdf&usg=AOvVaw3uUYEqas7NMuAmCCWAx_yl)\n",
    "- Use Anaconda Navigator to create new virtual environment\n",
    "- `conda env list` in terminal to list all environment available\n",
    "- `activate <env name>`\n",
    "- `env list` to confirm environment is activated\n",
    "\n",
    "Install dependencies:\n",
    "- `pip install pykernel`\n",
    "- `pip install pdf2image`\n",
    "- Download [poppler](https://github.com/oschwartz10612/poppler-windows/releases/) and unzip it as /Download/poppler-XXX\n",
    "- `pip install matplotlib`\n",
    "\n",
    "Section specific references:\n",
    "- [PDF Parsing](https://www.ismailmebsout.com/pdfs-parsing/)\n",
    "- [Convert PDF to Image using Python](https://www.geeksforgeeks.org/convert-pdf-to-image-using-python/)\n",
    "- [Poppler in path for pdf2image](https://stackoverflow.com/questions/53481088/poppler-in-path-for-pdf2image)\n",
    "- [Unable to get page count. Is poppler installed in PATH?](https://github.com/Belval/pdf2image/issues/142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image.exceptions import (PDFInfoNotInstalledError, PDFPageCountError, PDFSyntaxError)\n",
    "\n",
    "# read in and convert pdf to image\n",
    "sample_filepath = \"C:\\\\Users\\\\20jam\\\\Documents\\\\always-in-progress\\\\DSA3101 Data Science in Practice\\\\project - personal attempts\\\\original-data\\\\Tutorial 01\\\\ST2131_Tut1_T05_done.pdf\" # change this\n",
    "pages = convert_from_path(sample_filepath, poppler_path=r'C:\\Users\\20jam\\Downloads\\poppler-22.04.0\\Library\\bin') # change this\n",
    "\n",
    "# visualize page 0\n",
    "print(pages[0])\n",
    "\n",
    "# save pages\n",
    "for i in range(len(pages)):\n",
    "    pages[i].save('modified-data\\page'+ str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Document into Handwritting & Typed Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies:\n",
    "- `pip install cv2`\n",
    "- `pip install pandas numpy`\n",
    "- `pip install pandasql`\n",
    "- `pip install ipython`\n",
    "\n",
    "Section specific references:\n",
    "- [Printedand handwritten text extraction from images using Tesseract and Google Cloud Vision API](https://medium.com/@derrickfwang/printed-and-handwritten-text-extraction-from-images-using-tesseract-and-google-cloud-vision-api-ac059b62a535)\n",
    "- [HandwritingRecognition_GoogleCloudVision](https://github.com/DerrickFeiWang/HandwritingRecognition_GoogleCloudVision/blob/master/OCR_Printed%20and%20handwritten%20text%20extraction%20from%20images%20using%20Tesseract%20and%20Google%20Cloud%20Vision%20API_20200805.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os, cv2\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from IPython.display import Image\n",
    "\n",
    "# read in images\n",
    "os.chdir(r'C:\\Users\\....') # change to folder path containing images\n",
    "fileList = [x for x in os.listdir() if 'jpg'  in x.lower()]\n",
    "print(fileList[:5])\n",
    "Image(filename = fileList[0], width = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page segmentation \n",
    "def findHorizontalLines(img):\n",
    "    img = cv2.imread(img) \n",
    "    #convert image to greyscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # set threshold to remove background noise\n",
    "    thresh = cv2.threshold(gray,30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    # define rectangle structure (line) to look for: width 100, hight 1. This is a \n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (200,1))\n",
    "    # Find horizontal lines\n",
    "    lineLocations = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)\n",
    "    return lineLocations\n",
    "\n",
    "img = fileList[0]\n",
    "lineLocations = findHorizontalLines(img)\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.imshow(lineLocations, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting lines\n",
    "df_lineLocations = pd.DataFrame(lineLocations.sum(axis=1)).reset_index()\n",
    "df_lineLocations.columns = ['rowLoc', 'LineLength']\n",
    "df_lineLocations[df_lineLocations['LineLength'] > 0]\n",
    "\n",
    "df_lineLocations['line'] = 0\n",
    "df_lineLocations['line'][df_lineLocations['LineLength'] > 100] = 1\n",
    "\n",
    "df_lineLocations['cumSum'] = df_lineLocations['line'].cumsum()\n",
    "df_lineLocations.head()\n",
    "\n",
    "\n",
    "query = '''\n",
    "select row_number() over (order by cumSum) as SegmentOrder\n",
    ", min(rowLoc) as SegmentStart\n",
    ", max(rowLoc) - min(rowLoc) as Height\n",
    "from df_lineLocations\n",
    "where line = 0\n",
    "--and CumSum !=0\n",
    "group by cumSum\n",
    "'''\n",
    "df_SegmentLocations  = ps.sqldf(query, locals())\n",
    "df_SegmentLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop image\n",
    "def pageSegmentation1(img, w, df_SegmentLocations):\n",
    "    img = cv2.imread(img) \n",
    "    im2 = img.copy()\n",
    "    segments = []\n",
    "\n",
    "    for i in range(len(df_SegmentLocations)):\n",
    "        y = df_SegmentLocations['SegmentStart'][i]\n",
    "        h = df_SegmentLocations['Height'][i]\n",
    "\n",
    "        cropped = im2[y:y + h, 0:w] \n",
    "        segments.append(cropped)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(cropped)\n",
    "        plt.title(str(i+1))        \n",
    "\n",
    "    return segments\n",
    "\n",
    "img = fileList[0]\n",
    "w = lineLocations.shape[1]\n",
    "segments = pageSegmentation1(img, w, df_SegmentLocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Typed parts through Pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies:\n",
    "- `pip install re cv2 pytesseract`\n",
    "\n",
    "Section specific references:\n",
    "- [Printedand handwritten text extraction from images using Tesseract and Google Cloud Vision API](https://medium.com/@derrickfwang/printed-and-handwritten-text-extraction-from-images-using-tesseract-and-google-cloud-vision-api-ac059b62a535)\n",
    "- [HandwritingRecognition_GoogleCloudVision](https://github.com/DerrickFeiWang/HandwritingRecognition_GoogleCloudVision/blob/master/OCR_Printed%20and%20handwritten%20text%20extraction%20from%20images%20using%20Tesseract%20and%20Google%20Cloud%20Vision%20API_20200805.ipynb)\n",
    "- [Image Preprocessing for Pytesseract](https://www.youtube.com/watch?v=ADV-AjAXHdc)\n",
    "- [OC Python Textbook](https://github.com/wjbmattingly/ocr_python_textbook/blob/main/02_02_working%20with%20opencv.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# tell pytesseract where the engine is installed\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# extract text from image with two columns of contents\n",
    "def extractTextFromImg(segment):\n",
    "    text = pytesseract.image_to_string(segment, lang='eng')         \n",
    "    text = text.encode(\"gbk\", 'ignore').decode(\"gbk\", \"ignore\")\n",
    "    return text\n",
    "\n",
    "# preprocessing images in segment list (optional)\n",
    "segment = segments[1]\n",
    "text = extractTextFromImg(segment)\n",
    "print(text)\n",
    "segment = segments[2]\n",
    "text = extractTextFromImg(segment)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Written parts using Slicing & Breta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/obss/sahi\n",
    "https://github.com/Breta01/handwriting-ocr"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
